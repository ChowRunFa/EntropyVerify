{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec92088",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '6'\n",
    "from unsloth import FastLanguageModel, PatchFastRL\n",
    "PatchFastRL(\"GRPO\", FastLanguageModel)\n",
    "from unsloth import is_bfloat16_supported\n",
    "import torch\n",
    "max_seq_length = 8192 # Can increase for longer reasoning traces\n",
    "lora_rank = 64 # Larger rank = smarter, but slower\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"/cephfs/qiuwentao/models/models--Qwen--Qwen2.5-7B/snapshots/d149729398750b98c0af14eb82c78cfe92750796\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = False, # False for LoRA 16bit\n",
    "    fast_inference = True, # Enable vLLM fast inference\n",
    "    max_lora_rank = lora_rank,\n",
    "    gpu_memory_utilization = 0.8, # Reduce if out of memory\n",
    "    max_logprobs         = 50\n",
    ")\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ], # Remove QKVO if out of memory\n",
    "    lora_alpha = lora_rank,\n",
    "    use_gradient_checkpointing = \"unsloth\", # Enable long context finetuning\n",
    "    random_state = 3407,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5063948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \\\n",
    "f\"\"\"You are given a problem.\n",
    "Think about the problem and provide your working out.\n",
    "You must think in Bahasa Indonesia.\"\"\"\n",
    "from datasets import load_dataset,Dataset\n",
    "#打开/data/home/user0/llm-nas/panzy/llm/project/prorl-verl/recipe/prorl/data/math/dapo-math-17k.parquet\n",
    "dataset = load_dataset(\"parquet\", data_files = \"./datasets/open-r1/DAPO-Math-17k-Processed/en/train-00000-of-00001.parquet\")['train']\n",
    "def get_IE(split = \"train\") -> Dataset:\n",
    "    \n",
    "    data = dataset.map(lambda x: {\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": x[\"source_prompt\"][0]['content']},\n",
    "        ],\n",
    "        \"answer\": x['solution'],\n",
    "    }, remove_columns=dataset.column_names)\n",
    "    return data\n",
    "# dataset = get_gsm8k_questions()\n",
    "dataset=get_IE()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df4f0753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': [{'content': 'You are given a problem.\\nThink about the problem and provide your working out.\\nYou must think in Bahasa Indonesia.',\n",
       "   'role': 'system'},\n",
       "  {'content': 'Solve the following math problem step by step. The last line of your response should be of the form Answer: $Answer (without quotes) where $Answer is the answer to the problem.\\n\\nLet $ABCD$ be a unit square in the plane. Points $X$ and $Y$ are chosen independently and uniformly at random on the perimeter of $ABCD$. If the expected value of the area of triangle $\\\\triangle AXY$ can be expressed as $\\\\frac{m}{n}$ for relatively prime positive integers $m$ and $n$, compute $m+n$.\\n\\nRemember to put your answer on its own line after \"Answer:\".',\n",
       "   'role': 'user'}],\n",
       " 'answer': '113'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a3116cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def strict_format_reward_func(completions, **kwargs) -> list[float]:\n",
    "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
    "    pattern = r\"^<think>\\n.*?\\n</think>\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    matches = [re.match(pattern, r) for r in responses]\n",
    "    rewards=[0.5 if match else 0.0 for match in matches]\n",
    "    return  rewards\n",
    "def extract_xml_answer(text: str) -> str:\n",
    "    answer = text.split(\"Answer\")[-1]\n",
    "    return answer.strip()\n",
    "def correctness_ie_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n",
    "    responses = [completion[0]['content'] for completion in completions]\n",
    "    q = prompts[0][-1]['content']\n",
    "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
    "    print('-'*20, f\"Question:\\n{q}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nExtracted:\\n{extracted_responses[0]}\")\n",
    "    rewards=[2.0 if str(a) in r   else 0.0 for r, a in zip(extracted_responses, answer)]\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042867ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==============================================================================\n",
    "# New, extensible scoring function\n",
    "# ==============================================================================\n",
    "def _calculate_cluster_score(group_df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Calculates cluster_score for a group of samples under the same prompt_idx.\n",
    "\n",
    "    Args:\n",
    "        group_df (pd.DataFrame): DataFrame containing all samples for a single prompt_idx.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: A Series containing the cluster_score for each sample, with an index matching the input.\n",
    "        \n",
    "    Scoring Logic:\n",
    "    - Ranks samples by reward_score in descending order.\n",
    "    - The top-ranked sample gets a score of 1.0.\n",
    "    - The second-ranked gets 0.9, and so on, decreasing by 0.1 each time.\n",
    "    - If there are more than 10 samples, the minimum score is 0.0.\n",
    "    \n",
    "    Extensibility:\n",
    "    You can copy this function and modify the internal 'scores' generation logic\n",
    "    (e.g., to use exponential decay, normalization, etc.), then call your new function \n",
    "    in the main process.\n",
    "    \"\"\"\n",
    "    # 1. Sort by reward_score in descending order to determine rank\n",
    "    sorted_group = group_df.sort_values(by=\"reward_score\", ascending=False)\n",
    "    \n",
    "    # 2. Generate the list of scores [1.0, 0.9, 0.8, ...]\n",
    "    num_samples = len(sorted_group)\n",
    "    scores = [max(0.0, 1.0 - i * 0.1) for i in range(num_samples)]\n",
    "    \n",
    "    # 3. Create a Series of scores with an index corresponding to the sorted group\n",
    "    score_series = pd.Series(scores, index=sorted_group.index)\n",
    "    \n",
    "    # 4. Sort the score Series by the original index to ensure correct alignment with the original DataFrame\n",
    "    return score_series.sort_index()\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Other helper functions (unchanged)\n",
    "# ==============================================================================\n",
    "def _calculate_cluster_pos_distribution(df: pd.DataFrame, num_bins: int = 10) -> List[float]:\n",
    "    \"\"\"Calculates the distribution ratio of high-entropy tokens in different position bins within the text sequence.\"\"\"\n",
    "    high_df = df[df['high_entropy'] == 1].copy()\n",
    "    total_high_entropy_tokens = len(high_df)\n",
    "\n",
    "    if total_high_entropy_tokens == 0:\n",
    "        return [0.0] * num_bins\n",
    "\n",
    "    total_len = len(df)\n",
    "    high_df['pos_norm_internal'] = (high_df.index + 1) / total_len\n",
    "    \n",
    "    bins = np.linspace(0.0, 1.0, num_bins + 1)\n",
    "    bin_assignments = pd.cut(high_df['pos_norm_internal'], bins=bins, labels=False, include_lowest=True, right=True)\n",
    "    \n",
    "    bin_counts = bin_assignments.value_counts(sort=False)\n",
    "    proportions = bin_counts.reindex(range(num_bins), fill_value=0) / total_high_entropy_tokens\n",
    "    \n",
    "    return [round(p, 4) for p in proportions.tolist()]\n",
    "\n",
    "# ==============================================================================\n",
    "# Main processing function (refactored to support grouped scoring)\n",
    "# ==============================================================================\n",
    "def process_jsonl(input_files: List[str], output_file: str, top_percent: float = None, top_k: int = None):\n",
    "    \"\"\"\n",
    "    Processes JSONL files, adding grouped ranking and scoring functionality.\n",
    "\n",
    "    Workflow:\n",
    "    1. Read all data into an in-memory DataFrame.\n",
    "    2. Group by 'prompt_idx' and call _calculate_cluster_score to compute 'cluster_score'.\n",
    "    3. Iterate through each record to calculate 'high_entropy_pos_norm' and 'cluster_entropy_pos'.\n",
    "    4. Write the complete records, including all new fields, to the output file.\n",
    "    \"\"\"\n",
    "    if top_k is None and top_percent is None:\n",
    "        raise ValueError(\"Error: You must specify either 'top_k' or 'top_percent'.\")\n",
    "\n",
    "    print(f\"Starting to process files...\")\n",
    "\n",
    "    # --- Step 1: Read all data into memory ---\n",
    "    all_data = []\n",
    "    for input_file in input_files:\n",
    "        with open(input_file, \"r\", encoding=\"utf-8\") as fin:\n",
    "            for line in fin:\n",
    "                all_data.append(json.loads(line.strip()))\n",
    "    \n",
    "    if not all_data:\n",
    "        print(\"Input file(s) are empty. Processing finished.\")\n",
    "        return\n",
    "        \n",
    "    main_df = pd.DataFrame(all_data)\n",
    "\n",
    "    # --- Step 2: Group and calculate cluster_score ---\n",
    "    print(\"Grouping by prompt_idx and calculating cluster_score...\")\n",
    "    # Using groupby().apply() is a clear way to handle this custom scoring logic per group.\n",
    "    scores = main_df.groupby('prompt_idx').apply(_calculate_cluster_score).reset_index(level=0, drop=True)\n",
    "    main_df['cluster_score'] = scores\n",
    "    main_df['cluster_score'] = main_df['cluster_score'].round(4) # Format the score\n",
    "\n",
    "    # --- Step 3 & 4: Iterate through records, calculate other features, and write to file ---\n",
    "    print(\"Calculating other features and writing to file...\")\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as fout:\n",
    "        # Convert DataFrame to a list of dictionaries for easier processing\n",
    "        for record in tqdm(main_df.to_dict('records')):\n",
    "            entropy_list = record.get('entropy', [])\n",
    "            df_row = pd.DataFrame({'entropy': entropy_list})\n",
    "            total_len = len(df_row)\n",
    "\n",
    "            # Calculate n (number of high-entropy tokens)\n",
    "            n = 0\n",
    "            if total_len > 0:\n",
    "                if top_k is not None:\n",
    "                    n = min(top_k, total_len)\n",
    "                elif top_percent is not None:\n",
    "                    n = max(1, int(total_len * top_percent))\n",
    "\n",
    "            # Calculate high_entropy_pos_norm\n",
    "            high_entropy_pos_norm_list = []\n",
    "            if n > 0:\n",
    "                high_entropy_indices = df_row.nlargest(n, 'entropy').index.sort_values()\n",
    "                raw_list = ((high_entropy_indices + 1) / total_len).tolist()\n",
    "                high_entropy_pos_norm_list = [round(p, 4) for p in raw_list]\n",
    "                \n",
    "                # Prepare for distribution calculation\n",
    "                df_row['high_entropy'] = 0\n",
    "                df_row.loc[high_entropy_indices, 'high_entropy'] = 1\n",
    "            else:\n",
    "                 df_row['high_entropy'] = 0\n",
    "\n",
    "            # Calculate cluster_entropy_pos\n",
    "            cluster_pos_distribution = _calculate_cluster_pos_distribution(df_row, num_bins=10)\n",
    "\n",
    "            # Build the final output\n",
    "            final_output = {\n",
    "                \"prompt_idx\": record.get(\"prompt_idx\"),\n",
    "                \"sample_idx\": record.get(\"sample_idx\"),\n",
    "                \"reward_score\": record.get(\"reward_score\"),\n",
    "                \"cluster_score\": record.get(\"cluster_score\"),  # Insert the newly calculated score\n",
    "                \"cluster_entropy_pos\": cluster_pos_distribution,\n",
    "                \"high_entropy_pos_norm\": high_entropy_pos_norm_list,\n",
    "            }\n",
    "            \n",
    "            fout.write(json.dumps(final_output, ensure_ascii=False) + \"\\n\")\n",
    "             \n",
    "    print(f\"Processing complete. Results written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3085c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\n",
      "We will change the batch size of 2 to the `num_generations` of 4\n"
     ]
    }
   ],
   "source": [
    "from vllm import SamplingParams\n",
    "vllm_sampling_params = SamplingParams(\n",
    "    min_p = 0.1,\n",
    "    top_p = 1.0,\n",
    "    top_k = -1,\n",
    "    seed = 3407,\n",
    "    stop = [tokenizer.eos_token],\n",
    "    include_stop_str_in_output = True,\n",
    "    logprobs=20\n",
    ")\n",
    "\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "training_args = GRPOConfig(\n",
    "    use_vllm=True,\n",
    "    temperature = 1.0,\n",
    "    learning_rate = 5e-6,\n",
    "    weight_decay = 0.01,\n",
    "    warmup_ratio = 0.1,\n",
    "    lr_scheduler_type = \"linear\",\n",
    "    optim = \"adamw_8bit\",\n",
    "    logging_steps = 1,\n",
    "    per_device_train_batch_size = 2,\n",
    "    gradient_accumulation_steps = 4, # Increase to 4 for smoother training\n",
    "    num_generations = 4, # Decrease if out of memory\n",
    "    max_prompt_length = 1024,\n",
    "    max_completion_length = 5096,\n",
    "    num_train_epochs = 30, # Set to 1 for a full training run\n",
    "    # max_steps = 100,\n",
    "    save_steps = 100,\n",
    "    report_to = \"swanlab\", # Can use Weights & Biases\n",
    "    output_dir = \"outputs/20250727\",\n",
    "\n",
    "    # For optional training + evaluation\n",
    "    # fp16_full_eval = True,\n",
    "    # per_device_eval_batch_size = 4,\n",
    "    # eval_accumulation_steps = 1,\n",
    "    # eval_strategy = \"steps\",\n",
    "    # eval_steps = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d48866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For optional training + evaluation\n",
    "new_dataset = dataset.train_test_split(test_size = 0.01)\n",
    "\n",
    "trainer = GRPOTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    reward_funcs = [\n",
    "        strict_format_reward_func,\n",
    "        correctness_ie_reward_func,\n",
    "        entropy_distribution_reward\n",
    "    ],\n",
    "    args = training_args,\n",
    "    train_dataset = dataset,\n",
    "\n",
    "    # For optional training + evaluation\n",
    "    # train_dataset = new_dataset[\"train\"],\n",
    "    # eval_dataset = new_dataset[\"test\"],\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbc9b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained_merged(\"Qwen3_high_entropy\", tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
